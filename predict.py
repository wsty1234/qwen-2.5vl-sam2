
import json
import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor
import numpy as np
import os
import time
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from scipy.ndimage import gaussian_filter
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from tqdm import tqdm
import os
from qwen_vl_utils import process_vision_info  # å®˜æ–¹å·¥å…·å‡½æ•°
import re
from collections import defaultdict


def generate_points_with_qwen(model, processor, image, user_prompot):
    """
    ä½¿ç”¨ Qwen2.5-VL æ¨¡å‹ç”ŸæˆæŒ‡å®šå¯¹è±¡çš„è¾¹ç•Œæ¡†ï¼ˆç‚¹æç¤ºï¼‰ã€‚
    é€šè¿‡æ›´æ˜ç¡®çš„æç¤ºè¯ï¼Œæ—¨åœ¨è·å–è§„èŒƒçš„ JSON è¾“å‡ºã€‚

    Args:
        model: å·²åŠ è½½çš„Qwen2.5-VLæ¨¡å‹
        processor: å·²åŠ è½½çš„å¤„ç†å™¨
        image (PIL.Image): å¾…æ£€æµ‹çš„RGBå›¾åƒ
        user_prompot (str or list): éœ€è¦æ£€æµ‹çš„å¯¹è±¡ç±»åˆ«åˆ—è¡¨ï¼ˆå¦‚["car", "person"]ï¼‰æˆ–å•ä¸ªå­—ç¬¦ä¸²ã€‚

    Returns:
        list: Qwen-VL çš„åŸå§‹è¾“å‡ºåˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼ï¼‰ã€‚
    """

    # Ensure user_prompot is a string for the prompt
    if isinstance(user_prompot, list):
        # Join multiple prompts, e.g., ["car", "person"] -> "caræˆ–person"
        user_prompot_str = "ã€".join(user_prompot)
    else:
        user_prompot_str = user_prompot

    # # Create messages
    # messages = [
    #     {
    #         "role": "user",
    #         "content": [
    #             {"type": "image", "image": image},
    #             {
    #                 "type": "text",
    #                 "text": f"è¯·ä»å›¾ç‰‡ä¸­æ£€æµ‹æ‰€æœ‰çš„{user_prompot}ã€‚å¯¹äºæ¯ä¸€ä¸ªæ£€æµ‹åˆ°çš„{user_prompot}ï¼Œæ ¹æ®ç›®æ ‡å¤§å°ï¼Œè¯·ç”Ÿæˆ **1åˆ°5ä¸ªä»£è¡¨å…¶å®Œæ•´è½®å»“çš„ç‚¹**ã€‚è¿™äº›ç‚¹åº”è¯¥åˆ†å¸ƒåœ¨ç›®æ ‡çš„å„ä¸ªéƒ¨åˆ†ï¼Œä¾‹å¦‚è½¦å¤´ã€è½¦èº«å’Œè½¦å°¾ç­‰ã€‚å°†ç»“æœä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œå…¶ä¸­æ¯ä¸ªå¯¹è±¡çš„ 'points' é”®çš„å€¼å¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å«ç‚¹åæ ‡çš„**åˆ—è¡¨çš„åˆ—è¡¨**ï¼Œä¾‹å¦‚ï¼š[{{\"points\": [[x1, y1], [x2, y2]], \"label\": \"label_name\"}}, {{ \"points\": [[x3, y3], [x4, y4], [x5, y5]], \"label\": \"label_name\"}}]"
    #             },
    #         ],
    #     }
    # ]
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {
                    "type": "text",
                    "text": f"è¯·ä»å›¾ç‰‡ä¸­æ£€æµ‹æ‰€æœ‰çš„{user_prompot_str}ã€‚\n"
                              "å¯¹äºæ¯ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç›®æ ‡ï¼Œè¯·ç”Ÿæˆ **3åˆ°5ä¸ªä»£è¡¨å…¶å®Œæ•´è½®å»“çš„å…³é”®ç‚¹**ã€‚\n"
                              "è¿™äº›ç‚¹åº”è¯¥åˆ†å¸ƒåœ¨ç›®æ ‡çš„å„ä¸ªéƒ¨åˆ†ï¼Œä¾‹å¦‚æ±½è½¦çš„å››ä¸ªè§’å’Œä¸­å¿ƒã€‚\n"
                              "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ•°ç»„æ ¼å¼è¾“å‡ºç»“æœã€‚**ä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—ï¼Œåªè¿”å› JSONã€‚**\n"
                              "**æ¯ä¸ª JSON å¯¹è±¡å¿…é¡»ç²¾ç¡®åœ°åŒ…å« 'points' å’Œ 'label' ä¸¤ä¸ªé”®ã€‚**\n"
                              "   - 'points' çš„å€¼å¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å« `[x, y]` åæ ‡å¯¹çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ `[[x1, y1], [x2, y2], [x3, y3]]`ã€‚\n"
                              "     **æ¯ä¸ªç‚¹å¿…é¡»æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ `[x, y]` å­åˆ—è¡¨ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªç‚¹ã€‚**\n"
                              "   - 'label' çš„å€¼æ˜¯å¯¹è±¡çš„ç±»åˆ«å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ `\"car\"` æˆ– `\"road\"`ï¼Œ**ä¸è¦åŒ…å«é¢å¤–çš„æ–¹æ‹¬å·æˆ–å¼•å·ã€‚**\n"
                              "ä»¥ä¸‹æ˜¯ä¸¥æ ¼çš„ JSON ç¤ºä¾‹ï¼ˆè¯·ä¸¥æ ¼éµå¾ªæ­¤æ ¼å¼ï¼ŒåŒ…æ‹¬æ‰€æœ‰é€—å·å’Œæ‹¬å·ï¼‰ï¼š\n"
                              "```json\n"
                              "[\n"
                              "  {\"points\": [[100, 200], [150, 250], [100, 250], [150, 200]], \"label\": \"car\"},\n"
                              "  {\"points\": [[300, 400]], \"label\": \"road\"}  \n" # Example with a single point (still as [[x,y]])
                              "]\n"
                              "```\n"
                              "**å†æ¬¡å¼ºè°ƒï¼šåœ¨ 'points' åˆ—è¡¨ç»“æŸçš„ `]` ä¹‹åï¼Œå¿…é¡»ç´§è·Ÿä¸€ä¸ªé€—å· `,`ï¼Œç„¶åæ‰æ˜¯ 'label' é”®ã€‚**"
                },
            ],
        }
    ]    
    # Execute inference
    
    text = processor.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    # Assuming process_vision_info is defined elsewhere and works correctly
    # You'll need to make sure this function is correctly imported or defined.
    # For now, I'll put a placeholder if it's not provided.
    try:
        image_inputs, video_inputs = process_vision_info(messages)
    except NameError:
        print("Warning: 'process_vision_info' not found. Assuming simple image input structure.")
        # Fallback if process_vision_info is not provided
        # This part depends heavily on how your 'messages' are structured for processor
        # For typical single image input, it might look like this:
        image_inputs = [image] # Pass the PIL image directly if processor handles it
        video_inputs = None

    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    ).to(model.device)

    # Generate output
    print("------------------Qwen2.5b_vlæ­£åœ¨ç”Ÿæˆè¾“å‡º------------------")
    generated_ids = model.generate(
        **inputs,
        max_new_tokens=2048
        
        # Potentially add temperature=0.1 or top_p=0.9 to encourage more deterministic output
        # num_beams=1 # Or increase for more diverse, but potentially slower, generation
    )

    # Decode generated IDs
    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    return processor.batch_decode(
        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
    )


def pro_vl_results(rl_output):
    """
    å¤„ç† Qwen-VL çš„åŸå§‹è¾“å‡ºï¼Œæå– JSON å†…å®¹ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–ä¸º SAM2 æ‰€éœ€çš„ç‚¹æç¤ºã€‚
    å¢å¼ºäº†å¯¹ 'points' åµŒå¥—ç»“æ„ã€'label' å­—ç¬¦ä¸²åŒ–åˆ—è¡¨çš„é²æ£’æ€§ï¼Œå¹¶è¿‡æ»¤æ‰è´Ÿæ•°åæ ‡ç‚¹ã€‚

    Args:
        rl_output (list): Qwen-VL æ¨¡å‹çš„åŸå§‹è¾“å‡ºåˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

    Returns:
        dict: åŒ…å« 'points' å’Œ 'label' é”®çš„å­—å…¸ã€‚
              'points' æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯¹è±¡ç‚¹çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨æ˜¯ [[x, y], ...]ã€‚
              'label' æ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªç‚¹é›†å¯¹åº”æ ‡ç­¾é•¿åº¦çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ [[N1], [N2], ...]ã€‚
    """
    processed_points_for_sam2 = {'points': [], 'label': []}
    
    # 1. æå– JSON å†…å®¹
    json_content_str = None
    if rl_output and isinstance(rl_output[0], str):
        json_pattern = r'```json\n(.*?)\n```'
        json_match = re.search(json_pattern, rl_output[0], re.DOTALL)
        
        if json_match:
            extracted_json_content = json_match.group(1)
            # å°è¯•ä¿®å¤ ']]"label"' å˜æˆ ']], "label"' çš„æƒ…å†µ
            repaired_json_content = re.sub(r'\]\]\s*"label"', r']], "label"', extracted_json_content)
            repaired_json_content = re.sub(r'\]\s*"label"', r'], "label"', repaired_json_content)
            
            try:
                raw_point_results = json.loads(repaired_json_content)
            except json.JSONDecodeError as e:
                print(f"è­¦å‘Š: æå–çš„ JSON å†…å®¹è§£æå¤±è´¥: {e}. å†…å®¹: {repaired_json_content[:200]}...")
                raw_point_results = []
        else:
            # å¦‚æœæ²¡æœ‰ ```json``` æ ‡è®°ï¼Œå°è¯•ç›´æ¥è§£æï¼Œå°½ç®¡Qwen-VLé€šå¸¸ä¼šå¸¦
            try:
                raw_point_results = json.loads(rl_output[0])
            except json.JSONDecodeError:
                print("æœªåœ¨ ```json æ ‡è®°ä¹‹é—´æˆ–ä½œä¸ºçº¯ JSON å­—ç¬¦ä¸²æ‰¾åˆ° JSON å†…å®¹ã€‚")
                raw_point_results = []
    else:
        print(f"è­¦å‘Š: Qwen-VL è¾“å‡ºæ ¼å¼å¼‚å¸¸: {rl_output}. æœŸæœ›ä¸€ä¸ªåŒ…å«å­—ç¬¦ä¸²çš„åˆ—è¡¨ã€‚")
        raw_point_results = []

    # ç¡®ä¿ raw_point_results æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œä»¥ä¾¿ç»Ÿä¸€å¤„ç†
    if not isinstance(raw_point_results, list):
        raw_point_results = [raw_point_results]

    # 2. éå†è§£æåçš„ç»“æœï¼Œæå–å¹¶æ ¼å¼åŒ–ç‚¹ä¿¡æ¯
    for obj_data in raw_point_results:
        if 'points' in obj_data and isinstance(obj_data['points'], list):
            current_obj_raw_points = obj_data['points']
            
            # --- æ‰å¹³åŒ– points åˆ—è¡¨ START ---
            flattened_points = []
            def flatten(items):
                """é€’å½’æ‰å¹³åŒ–åˆ—è¡¨ï¼Œç›´åˆ°é‡åˆ°éåˆ—è¡¨å…ƒç´ æˆ–[x, y]å¯¹"""
                for item in items:
                    if isinstance(item, list) and len(item) == 2 and all(isinstance(coord_val, (int, float)) for coord_val in item):
                        # --- æ–°å¢çš„è´Ÿæ•°åæ ‡è¿‡æ»¤é€»è¾‘ START ---
                        if item[0] >= 0 and item[1] >= 0: # ç¡®ä¿ x å’Œ y åæ ‡éƒ½éè´Ÿ
                            # æ‰¾åˆ°äº†ä¸€ä¸ª [x, y] å¯¹ï¼Œä¸”åæ ‡æœ‰æ•ˆï¼Œç›´æ¥æ·»åŠ 
                            flattened_points.append(item)
                        else:
                            print(f"è­¦å‘Š: å‘ç°è´Ÿæ•°æˆ–æ— æ•ˆåæ ‡ï¼Œå·²è¿‡æ»¤: {item}")
                        # --- æ–°å¢çš„è´Ÿæ•°åæ ‡è¿‡æ»¤é€»è¾‘ END ---
                    elif isinstance(item, list):
                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç»§ç»­é€’å½’æ‰å¹³åŒ–
                        flatten(item)
                    # å¦åˆ™ï¼Œè·³è¿‡éåˆ—è¡¨æˆ–é [x, y] çš„é¡¹ï¼Œæˆ–å¯ä»¥æ·»åŠ è­¦å‘Š
            
            flatten(current_obj_raw_points)
            # --- æ‰å¹³åŒ– points åˆ—è¡¨ END ---

            # --- è§£æ label å­—æ®µ START ---
            extracted_label = "unknown" # é»˜è®¤å€¼
            raw_label = obj_data.get('label', '')
            if isinstance(raw_label, str):
                # å°è¯•è§£æ "['road']" æˆ– "road"
                try:
                    # å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·ä»¥ä¾¿JSONè§£æ
                    parsed_label_list = json.loads(raw_label.replace("'", '"')) 
                    if isinstance(parsed_label_list, list) and len(parsed_label_list) > 0:
                        extracted_label = str(parsed_label_list[0]) # å–åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
                    else:
                        extracted_label = raw_label # å¦‚æœè§£æå¤±è´¥æˆ–ä¸æ˜¯åˆ—è¡¨ï¼Œå°±ç”¨åŸå§‹å­—ç¬¦ä¸²
                except json.JSONDecodeError:
                    extracted_label = raw_label # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²ï¼Œå°±ç”¨åŸå§‹å­—ç¬¦ä¸²
            elif raw_label is not None:
                # å¦‚æœ label ç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼ˆå¦‚ "road"ï¼‰ï¼Œæˆ–å…¶ä»–éå­—ç¬¦ä¸²ç±»å‹
                extracted_label = str(raw_label)
            # --- è§£æ label å­—æ®µ END ---

            if flattened_points: # å¦‚æœå½“å‰å¯¹è±¡æœ‰æœ‰æ•ˆçš„ç‚¹
                processed_points_for_sam2['points'].append(flattened_points)
                # SAM2é€šå¸¸æœŸæœ›æ¯ä¸ªç‚¹ä¸€ä¸ªæ ‡ç­¾ï¼Œä¸”éƒ½æ˜¯å‰æ™¯ï¼ˆ1ï¼‰
                # æˆ‘ä»¬è¿™é‡Œå­˜å‚¨çš„æ˜¯è¯¥ç‚¹é›†åŒ…å«çš„ç‚¹æ•°é‡ï¼Œåœ¨merge_annotationsä¸­ä¼šè½¬åŒ–ä¸º1
                processed_points_for_sam2['label'].append([len(flattened_points)])
            else:
                print(f"è­¦å‘Š: å¯¹è±¡æ•°æ®ä¸­ 'points' å­—æ®µä¸ºç©ºæˆ–æ— æ•ˆï¼Œæˆ–è€…æœªèƒ½æˆåŠŸæ‰å¹³åŒ–: {obj_data}")
        else:
            print(f"è­¦å‘Š: å¯¹è±¡æ•°æ®ä¸­ç¼ºå°‘ 'points' é”®æˆ–å…¶æ ¼å¼ä¸æ­£ç¡®: {obj_data}")

    return processed_points_for_sam2


import json
import re

def pro_vl_results_32B(rl_output):
    """
    å¤„ç† Qwen-VL çš„åŸå§‹è¾“å‡ºï¼Œæå– JSON å†…å®¹ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–ä¸º SAM2 æ‰€éœ€çš„ç‚¹æç¤ºã€‚
    å¢å¼ºäº†å¯¹ 'points' åµŒå¥—ç»“æ„ã€'label' å­—ç¬¦ä¸²åŒ–åˆ—è¡¨çš„é²æ£’æ€§ï¼Œè¿‡æ»¤è´Ÿæ•°åæ ‡ï¼Œ
    å¹¶æ›´çµæ´»åœ°ä¿®å¤ JSON æ ¼å¼ä¸­ç¼ºå¤±çš„é€—å·ã€‚

    Args:
        rl_output (list): Qwen-VL æ¨¡å‹çš„åŸå§‹è¾“å‡ºåˆ—è¡¨ï¼Œé€šå¸¸åŒ…å«ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

    Returns:
        dict: åŒ…å« 'points' å’Œ 'label' é”®çš„å­—å…¸ã€‚
              'points' æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯¹è±¡ç‚¹çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨æ˜¯ [[x, y], ...]ã€‚
              'label' æ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªç‚¹é›†å¯¹åº”æ ‡ç­¾é•¿åº¦çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ [[N1], [N2], ...]ã€‚
    """
    processed_points_for_sam2 = {'points': [], 'label': []}
    # print(f"ğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Š{rl_output[0]}")
    # 1. æå– JSON å†…å®¹
    json_content_str = None
    if rl_output and isinstance(rl_output[0], str):
        json_pattern = r'```json\n(.*?)\n```'
        json_match = re.search(json_pattern, rl_output[0], re.DOTALL)
        
        if json_match:
            extracted_json_content = json_match.group(1)
            
            # --- æ›´é€šç”¨çš„ JSON ä¿®å¤é€»è¾‘ START ---
            # ä¿®å¤ '[...]"label"' å˜æˆ '[...], "label"' çš„æƒ…å†µ
            # åŒ¹é…ä»»ä½•ä¸€ä¸ªæˆ–å¤šä¸ª ']' åé¢ç›´æ¥è·Ÿç€ä¸€ä¸ª '"' (å¦‚æœå‰é¢ä¸æ˜¯ ',')
            # è¿™æ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„æ¨¡å¼ï¼Œä»¥æ•æ‰ ']]"label"' å’Œ ']"label"' ç”šè‡³å¯èƒ½æ˜¯ ']]]"label"'
            repaired_json_content = re.sub(r'\]\s*(?<!,)"', r'], "', extracted_json_content)
            # å†æ¬¡ä¿®å¤ï¼Œä»¥é˜²æœ‰åµŒå¥—çš„ ]] ä¸”ä¹‹å‰æ²¡æœ‰é€—å·ï¼Œä¾‹å¦‚ [[x,y]],"label" å˜æˆ [[x,y]],,"label"
            # ç¡®ä¿åªåœ¨å¿…è¦æ—¶æ·»åŠ é€—å·ï¼Œé¿å…é‡å¤
            repaired_json_content = re.sub(r'\]\s*,\s*\]\s*,\s*"', r']], "', repaired_json_content) # For cases like ']],,"label"' from previous repair
            
            repaired_json_content = re.sub(r'"label":\s*"\[\'(.*?)\'\]"', r'"label": "\1"', repaired_json_content)

            # --- æ›´é€šç”¨çš„ JSON ä¿®å¤é€»è¾‘ END ---
            
            try:
                raw_point_results = json.loads(repaired_json_content)
            except json.JSONDecodeError as e:
                print(f"è­¦å‘Š: æå–çš„ JSON å†…å®¹è§£æå¤±è´¥: {e}. å†…å®¹: {repaired_json_content[:200]}...")
                raw_point_results = []
        else:
            # If no ```json``` marker, try direct parsing, although Qwen-VL usually provides one
            try:
                raw_point_results = json.loads(rl_output[0])
            except json.JSONDecodeError:
                print("æœªåœ¨ ```json æ ‡è®°ä¹‹é—´æˆ–ä½œä¸ºçº¯ JSON å­—ç¬¦ä¸²æ‰¾åˆ° JSON å†…å®¹ã€‚")
                raw_point_results = []
    else:
        print(f"è­¦å‘Š: Qwen-VL è¾“å‡ºæ ¼å¼å¼‚å¸¸: {rl_output}. Expected a list containing a string.")
        raw_point_results = []

    # Ensure raw_point_results is a list for uniform processing
    if not isinstance(raw_point_results, list):
        raw_point_results = [raw_point_results]

    # 2. Iterate through parsed results, extract and format point information
    for obj_data in raw_point_results:
        if 'points' in obj_data and isinstance(obj_data['points'], list):
            current_obj_raw_points = obj_data['points']
            
            # --- Flatten points list START ---
            flattened_points = []
            def flatten(items):
                """Recursively flattens lists until non-list elements or [x, y] pairs are found."""
                for item in items:
                    # Check for [x, y] pair and non-negative coordinates
                    if isinstance(item, list) and len(item) == 2 and all(isinstance(coord_val, (int, float)) for coord_val in item):
                        if item[0] >= 0 and item[1] >= 0:
                            flattened_points.append(item)
                        else:
                            print(f"è­¦å‘Š: å‘ç°è´Ÿæ•°æˆ–æ— æ•ˆåæ ‡ï¼Œå·²è¿‡æ»¤: {item}")
                    elif isinstance(item, list):
                        flatten(item)
                    # Else, skip non-list or non-[x, y] items
            
            flatten(current_obj_raw_points)
            # --- Flatten points list END ---

            # --- Parse label field START ---
            extracted_label = "unknown" # Default value
            raw_label = obj_data.get('label', '')
            # If label is a string, try to clean it
            if isinstance(raw_label, str):
                # We tried to repair `["'road'"]` to `"road"` earlier with regex.
                # If that failed, this attempts to parse it as JSON
                try:
                    parsed_label_list = json.loads(raw_label.replace("'", '"')) 
                    if isinstance(parsed_label_list, list) and len(parsed_label_list) > 0:
                        extracted_label = str(parsed_label_list[0])
                    else:
                        extracted_label = raw_label 
                except json.JSONDecodeError:
                    extracted_label = raw_label # If not a valid JSON string, use original
            elif raw_label is not None:
                extracted_label = str(raw_label)
            # --- Parse label field END ---

            if flattened_points: # If current object has valid points
                processed_points_for_sam2['points'].append(flattened_points)
                # SAM2 usually expects one label per point, all foreground (1)
                # We store the number of points in this set; it will be converted to 1s in merge_annotations
                processed_points_for_sam2['label'].append([len(flattened_points)]) # Keep the length for now
            else:
                print(f"è­¦å‘Š: å¯¹è±¡æ•°æ®ä¸­ 'points' å­—æ®µä¸ºç©ºæˆ–æ— æ•ˆï¼Œæˆ–è€…æœªèƒ½æˆåŠŸæ‰å¹³åŒ–: {obj_data}")
        else:
            print(f"è­¦å‘Š: å¯¹è±¡æ•°æ®ä¸­ç¼ºå°‘ 'points' é”®æˆ–å…¶æ ¼å¼ä¸æ­£ç¡®: {obj_data}")

    return processed_points_for_sam2
def timeit(func):
    """Decorator to measure function execution time."""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed_time = time.time() - start_time
        return result
    return wrapper

def merge_annotations(annotations):
    """
    åˆå¹¶å…·æœ‰ç›¸åŒ frame_idx çš„æ³¨è§£ã€‚
    å°†æ¯ä¸ª frame_idx ä¸‹çš„æ‰€æœ‰ç‚¹çš„ 'points' å’Œ 'labels' èšåˆèµ·æ¥ã€‚
    ç”Ÿæˆçš„ 'labels' æ ¼å¼ä¸º [1, 1, ..., 1]ï¼Œæ•°é‡ä¸åˆå¹¶åçš„ç‚¹æ•°åŒ¹é…ã€‚

    Args:
        annotations (list): åŸå§‹çš„æ³¨è§£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'obj_id', 'frame_idx', 'points', 'labels', 'box'ã€‚

    Returns:
        list: åˆå¹¶åçš„æ³¨è§£åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ª frame_idx ä¸‹çš„æ‰€æœ‰å¯¹è±¡ã€‚
              å…¶ 'points' åŒ…å«æ‰€æœ‰å¯¹è±¡çš„æ‰å¹³åŒ–ç‚¹åˆ—è¡¨ï¼Œ'labels' åŒ…å«ä¸è¿™äº›ç‚¹ä¸€ä¸€å¯¹åº”çš„ '1' æ ‡ç­¾ã€‚
              'obj_id' è¡¨ç¤ºè¯¥å¸§ä¸­åŸå§‹å¯¹è±¡çš„æ€»æ•°ï¼ˆç”¨äºå…ƒæ•°æ®ï¼ŒSAM2å¯èƒ½ä¸ç›´æ¥ä½¿ç”¨æ­¤IDï¼‰ã€‚
    """
    merged_by_frame = defaultdict(
        lambda: {'points': [], 'labels': [], 'box': [], 'original_obj_count': 0}
    )

    for annot in annotations:
        frame_idx = annot['frame_idx']
        
        # å°†å½“å‰æ³¨è§£çš„ç‚¹æ·»åŠ åˆ°è¯¥å¸§çš„æ€»ç‚¹åˆ—è¡¨ä¸­ (æ‰å¹³åŒ–)
        # annot['points'] å·²ç»æ˜¯åƒ [[x1, y1], [x2, y2]] è¿™æ ·çš„åˆ—è¡¨
        merged_by_frame[frame_idx]['points'].extend(annot['points'])
        
        # æ ¹æ®å½“å‰æ³¨è§£çš„ç‚¹æ•°é‡ï¼Œæ·»åŠ ç›¸åº”æ•°é‡çš„ '1' åˆ°è¯¥å¸§çš„æ€»æ ‡ç­¾åˆ—è¡¨ä¸­
        # annot['points'] çš„é•¿åº¦å°±æ˜¯è¯¥åŸå§‹å¯¹è±¡æ‰€åŒ…å«çš„ç‚¹æ•°
        num_points_in_current_object = len(annot['points'])
        merged_by_frame[frame_idx]['labels'].extend([1] * num_points_in_current_object)
        
        # å¢åŠ åŸå§‹å¯¹è±¡è®¡æ•°
        merged_by_frame[frame_idx]['original_obj_count'] += 1
        
        # æ¡†ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼Œè¿™é‡Œç®€å•åœ°å–ç¬¬ä¸€ä¸ªï¼Œæˆ–è€…æ ¹æ®éœ€è¦è¿›è¡Œåˆå¹¶ï¼‰
        if annot['box']:
            # è¿™é‡Œçš„é€»è¾‘éœ€è¦æ ¹æ®ä½ å®é™…çš„ box å¤„ç†éœ€æ±‚æ¥å®š
            pass # ä¿æŒä¸åŠ¨ï¼Œæˆ–æ ¹æ®ä½ çš„åˆå¹¶ç­–ç•¥å¤„ç†

    final_merged_annotations = []
    for frame_idx in sorted(merged_by_frame.keys()):
        merged_data = merged_by_frame[frame_idx]
        final_merged_annotations.append({
            'obj_id': merged_data['original_obj_count'], # æ­¤å¤„çš„ obj_id ä½œä¸ºå…ƒæ•°æ®ï¼Œè¡¨ç¤ºåŸå§‹å¯¹è±¡çš„æ€»æ•°
            'frame_idx': frame_idx,
            'points': merged_data['points'], # åŒ…å«æ‰€æœ‰åŸå§‹å¯¹è±¡çš„æ‰å¹³åŒ–ç‚¹åˆ—è¡¨
            'labels': merged_data['labels'], # åŒ…å«ä¸æ‰€æœ‰ç‚¹ä¸€ä¸€å¯¹åº”çš„ '1' æ ‡ç­¾ï¼Œå¦‚ [1, 1, 1, 1, 1, 1, 1, 1, 1]
            'box': merged_data['box'] # ä¿æŒä¸ºåŸå§‹æ”¶é›†çš„boxï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        })
    return final_merged_annotations

def init_models():
    """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
    # SAM2
    SAM2_CHECKPOINT = "/home/iking/Grounded-SAM-2/checkpoints/sam2.1_hiera_large.pt"
    SAM2_CONFIG = "configs/sam2.1/sam2.1_hiera_l.yaml"
    sam_predictor = build_sam2(SAM2_CONFIG, SAM2_CHECKPOINT)
    
    return sam_predictor

CONFIG = {
    "prompts": ["sky"], # æç¤ºè¯
    "keyframe_interval": 20,   # æç¤ºå¸§çš„é¢‘ç‡
    "sam_config": "checkpoints/sam2.1_hiera_large.pt",
    "sam_checkpoint": "configs/sam2.1/sam2.1_hiera_l.yaml"
}

def save_colored_mask_png(mask_bool, out_path, color=(255, 0, 0)):
    """
    mask_bool: (H, W) çš„ bool/0-1 æ©ç 
    color: RGB å›ºå®šé¢œè‰²
    out_path: ä¿å­˜è·¯å¾„ï¼ˆ.pngï¼‰
    """
    h, w = mask_bool.shape
    rgba = np.zeros((h, w, 4), dtype=np.uint8)
    rgba[..., :3] = np.array(color, dtype=np.uint8)
    rgba[..., 3] = (mask_bool.astype(np.uint8) * 255)  # å‰æ™¯ä¸é€æ˜ï¼ŒèƒŒæ™¯é€æ˜
    Image.fromarray(rgba, mode='RGBA').save(out_path)

# 4B) ä¿å­˜ä¸ºå•é€šé“æ©ç ï¼ˆç°åº¦/ç´¢å¼•ï¼‰
def save_binary_mask_png(mask_bool, out_path, fg_value=255):
    """
    å•é€šé“ 8-bitï¼Œå‰æ™¯ fg_valueï¼ŒèƒŒæ™¯ 0
    """
    img = (mask_bool.astype(np.uint8) * fg_value)
    Image.fromarray(img, mode='L').save(out_path)

def quad_to_xyxy(quad):
        xs = [p[0] for p in quad]
        ys = [p[1] for p in quad]
        return [min(xs), min(ys), max(xs), max(ys)]

def main():
    # 0. é…ç½®
    img_file = "/home/iking/qwen_vl_sam/demo0.png"
    output_dir = "./outputs"
    # 1. åˆå§‹åŒ–SAM2æ¨¡å‹
    sam_predictor= init_models()
    sam2_predictor = SAM2ImagePredictor(sam_predictor)
    
    qwen_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        "Qwen/Qwen2.5-VL-7B-Instruct",
        torch_dtype=torch.bfloat16,
        attn_implementation="flash_attention_2",
        device_map="auto",
    )
    qwen_processor = AutoProcessor.from_pretrained(
        "Qwen/Qwen2.5-VL-7B-Instruct"
        )

    annotations = []
    
    # 2. è¯»å–å›¾åƒ
    frame = cv2.imread(img_file)
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_pil_from_array = Image.fromarray(frame_rgb)
    objects_to_detect = CONFIG["prompts"]
    print(f"objects_to_detect:{objects_to_detect}")
    # ä½¿ç”¨Qwenæ¨¡å‹ç”Ÿæˆç‚¹æç¤º
    vl_results = generate_points_with_qwen(
        model=qwen_model,
        processor=qwen_processor,
        image=frame_pil_from_array,
        user_prompot=objects_to_detect
    )
    print(f"vl_results:{vl_results}")
    # processed_points = pro_vl_results(vl_results)
    processed_points = pro_vl_results_32B(vl_results)
    print(f"å¤„ç†åçš„LLMç»“æœ:{processed_points}")

    boxes = [quad_to_xyxy(quad) for quad in processed_points['points']]
    boxes_np = np.array(boxes, dtype=np.float32)  # shape: (N, 4), format [x_min, y_min, x_max, y_max    

    raw_labels = [l[0] for l in processed_points['label']]  # å±•å¹³æ¯ä¸ªçš„é¦–å…ƒç´ 
    names = [str(x) for x in raw_labels]  # è¿™é‡Œç›´æ¥è½¬å­—ç¬¦ä¸²

    sam2_predictor.set_image(frame_pil_from_array)
    if torch.cuda.is_available(): # æˆ–è€… torch.cuda.is_available() for GPU
        torch.cuda.empty_cache() # æˆ–è€… torch.cuda.empty_cache()
    print("--------------------- Qwen-VL æ¨¡å‹æ˜¾å­˜å·²é‡Šæ”¾---------------------")
    # --- æ˜¾å­˜é‡Šæ”¾ç»“æŸ ---

    masks, scores, logits = sam2_predictor.predict(
        point_coords=None,
        point_labels=None,
        box=boxes_np,
        multimask_output=False,
    )
    
    if masks.ndim == 4:
        masks = masks.squeeze(1)

    save_dir = "/home/iking/qwen_vl_sam"
    fixed_color = (0, 255, 0)  # å›ºå®šé¢œè‰²ï¼šç»¿è‰²
    for i, mask in enumerate(masks):
        # ç¡®ä¿æ˜¯ bool
        mask_bool = (mask > 0.5) if mask.dtype != np.bool_ else mask
        name = names[i] if i < len(names) else f"mask_{i}"

        # A) å½©è‰²å¸¦é€æ˜
        out_path_rgba = os.path.join(save_dir, f"{name}.png")
        save_colored_mask_png(mask_bool, out_path_rgba, color=fixed_color)

if __name__ == "__main__":
    main()